# -*- coding: utf-8 -*-
"""Spam Classifier

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SPMD79q-xfiMRQSYZ8Yitkv8hkVEfUMJ
"""

import tarfile
import os

# open easy ham folder
file_path = '/content/20021010_easy_ham.tar.bz2'

# Specify the directory where you want to extract the contents
extracted_dir = '/content/'

# Create the extraction directory if it doesn't exist
os.makedirs(extracted_dir, exist_ok=True)

# Extract the contents of the .tar.bz2 file
with tarfile.open(file_path, 'r:bz2') as tar_ref:
    tar_ref.extractall(extracted_dir)

# Now, you can work with the extracted files
# For example, let's print the contents of the extracted directory
print(f"Contents of {extracted_dir}:")
for root, dirs, files in os.walk(extracted_dir):
    for file in files:
        print(os.path.join(root, file))


#open spam folder
file_path = '/content/20021010_spam.tar.bz2'

# Specify the directory where you want to extract the contents
extracted_dir = '/content/'

# Create the extraction directory if it doesn't exist
os.makedirs(extracted_dir, exist_ok=True)

# Extract the contents of the .tar.bz2 file
with tarfile.open(file_path, 'r:bz2') as tar_ref:
    tar_ref.extractall(extracted_dir)

# Now, you can work with the extracted files
# For example, let's print the contents of the extracted directory
print(f"Contents of {extracted_dir}:")
for root, dirs, files in os.walk(extracted_dir):
    for file in files:
        print(os.path.join(root, file))

import os

#store ham files
def read_and_store_ham_files(directory):
    """
    Reads each text file in the specified directory and stores the content.

    Parameters:
    - directory: The path to the directory containing the text files.

    Returns:
    - A dictionary where keys are file names and values are the content of the files.
    """
    file_contents = {}

    # Iterate over each file in the directory
    for file_name in os.listdir(directory):
        file_path = os.path.join(directory, file_name)

        # Check if it's a file and ends with ".txt" (you can adjust this condition)
        if os.path.isfile(file_path):
            with open(file_path, 'r', encoding='latin-1') as file:
                # Read the content of the file
                content = file.read()
                # Store the content in the dictionary
                file_contents[file_name] = content

    return file_contents

# Specify the directory where you extracted the text files
extracted_dir = '/content/easy_ham'

# Call the function to read and store the content of each text file
text_files_content = read_and_store_ham_files(extracted_dir)

# Now, text_files_content is a dictionary where keys are file names and values are the content
# You can use this dictionary to create feature vectors later based on your specific requirements


#store ham files
def read_and_store_text_files(directory):
    """
    Reads each text file in the specified directory and stores the content.

    Parameters:
    - directory: The path to the directory containing the text files.

    Returns:
    - A dictionary where keys are file names and values are the content of the files.
    """
    file_contents = {}

    # Iterate over each file in the directory
    for file_name in os.listdir(directory):
        file_path = os.path.join(directory, file_name)

        # Check if it's a file and ends with ".txt" (you can adjust this condition)
        if os.path.isfile(file_path):
            with open(file_path, 'r', encoding='latin-1') as file:
                # Read the content of the file
                content = file.read()
                # Store the content in the dictionary
                file_contents[file_name] = content

    return file_contents

# Specify the directory where you extracted the text files
extracted_dir_ham = '/content/easy_ham'
extracted_dir_spam = '/content/spam'
# Call the function to read and store the content of each text file
ham_files_content = read_and_store_text_files(extracted_dir_ham)

spam_files_content = read_and_store_text_files(extracted_dir_spam)

for file_name, content in list(spam_files_content.items())[:3]:
  print(f"File Name: {file_name}")
  print(f"Content:\n{content}\n")

import pandas as pd


# Convert dictionaries to DataFrames
spam_df = pd.DataFrame(list(spam_files_content.items()), columns=['file name', 'Content'])
ham_df = pd.DataFrame(list(ham_files_content.items()), columns=['file name', 'Content'])

spam_df["label"] = 1
ham_df["label"] = 0

spam_df = spam_df.drop('file name', axis = 1)
ham_df = ham_df.drop('file name', axis = 1)

print(spam_df.head())
print(ham_df.head())


# Concatenate the two DataFrames vertically
combined_dataset = pd.concat([spam_df[['Content', 'label']], ham_df[['Content', 'label']]], ignore_index=True)



# Print the combined dataset
print(combined_dataset.head())
print(combined_dataset.tail())

final_spam_ham_df = combined_dataset.sample(frac=1, random_state=42).reset_index(drop=True)
X, y = final_spam_ham_df["Content"], final_spam_ham_df["label"]

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer()

# Apply TF-IDF vectorization to the 'Content' column
X_features = tfidf_vectorizer.fit_transform(X).toarray()

# Print the feature vectors (X_features)
print("Feature Vectors:")
print(X_features)

X_train, X_test, y_train, y_test = X_features[:1525], X_features[1525:], y[:1525], y[1525: ]

from sklearn.linear_model import SGDClassifier

some_email = X_features[0]

sgd_clf = SGDClassifier(random_state = 42)
sgd_clf.fit(X_train, y_train)

sgd_clf.predict([some_email])

from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv = 3)

from sklearn.metrics import confusion_matrix
y_train_spam = (y_train == 1)
confusion_matrix(y_train_spam, y_train_pred)

from sklearn.metrics import precision_score, recall_score

precision_score(y_train_spam, y_train_pred)

recall_score(y_train_spam, y_train_pred)

from sklearn.metrics import f1_score
f1_score(y_train_spam, y_train_pred)

y_scores = sgd_clf.decision_function([some_email])
y_scores

threshold = 1
y_some_email_pred = (y_scores > threshold)
y_some_email_pred



y_scores = cross_val_predict(sgd_clf, X_train, y_train_spam, cv = 3, method = "decision_function")

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

fpr, tpr, thresholds = roc_curve(y_train_spam, y_scores)

def plot_roc_curve(fpr, tpr, label = None):
  plt.plot(fpr, tpr, linewidth = 2, label = label)
  plt.plot([0, 1], [0, 1], 'k--')
  plt.xlabel('False Positive Rate')
  plt.ylabel('True Positive Rate')
  plt.grid(True)

plot_roc_curve(fpr, tpr)
plt.show()

from sklearn.metrics import roc_auc_score
roc_auc_score (y_train_spam, y_scores)

#try other classifiers

from sklearn.ensemble import RandomForestClassifier

forest_clf = RandomForestClassifier(random_state = 42)
y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_spam, cv = 3, method = "predict_proba")

y_scores_forest = y_probas_forest[:, 1]
fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_spam, y_scores_forest)

plt.plot(fpr, tpr, "b:", label = 'SGD')
plot_roc_curve(fpr_forest, tpr_forest, "Random Forest")
plt.legend(loc = "lower right")
plt.show()

roc_auc_score(y_train_spam, y_scores_forest)

y_train_predict = cross_val_predict(forest_clf, X_train, y_train_spam, cv =3)

precision_score(y_train_spam, y_train_predict)
recall_score(y_train_spam, y_train_predict)