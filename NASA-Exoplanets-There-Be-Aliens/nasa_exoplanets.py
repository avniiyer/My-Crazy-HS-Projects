# -*- coding: utf-8 -*-
"""NASA Exoplanets

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13NyXWvMNEsEy5am6wQGlZHW8yo4daSEu
"""

import pandas as pd
import os
import tarfile
import zipfile

zip_file_path = 'archive.zip'
extract_path = '/content/'

with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

def load_income_data():
  for root, dirs, files in os.walk(extract_path):
      for file in files:
        return(os.path.join(root,file))


load_income_data()

exoTest = pd.read_csv('exoTest.csv')
print(exoTest)
print(exoTest.info())

'''for index, row in exoTest.iterrows():
    exoTest.loc[index] = row.replace(1,0)
    exoTest.loc[index] = row.replace(2, 1)'''
exoTest['LABEL'] = exoTest['LABEL'].replace(1, 0)
exoTest['LABEL'] = exoTest['LABEL'].replace(2, 1)

print(exoTest)

exoTest.tail(15)

exoTrain = pd.read_csv('exoTrain.csv')
print(exoTrain)

exoTrain['LABEL'] = exoTrain['LABEL'].replace(1, 0)
exoTrain['LABEL'] = exoTrain['LABEL'].replace(2, 1)
print(exoTrain)

X_train, y_train = exoTrain.drop('LABEL', axis = 1), exoTrain['LABEL']
X_test, y_test = exoTest.drop('LABEL', axis = 1), exoTest['LABEL']

print(y_train)

"""using SGD classifier"""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
pca = PCA(n_components=2)

# Assuming 'pca' is your PCA object and 'X_train' is your training data
X_pca = pca.fit_transform(X_train)

# Plot data points with label "0" in blue
plt.scatter(X_pca[y_train == 0, 0], X_pca[y_train == 0, 1], color='blue', label='Class 0')

# Plot data points with label "1" in red
plt.scatter(X_pca[y_train == 1, 0], X_pca[y_train == 1, 1], color='red', label='Class 1')

plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Plot of Training Data with Class Labels')
plt.legend()
plt.show()

X_test_pca = pca.transform(X_test)

X_test_pca.shape
y

from sklearn import metrics
from sklearn.linear_model import LogisticRegression

logistic_model = LogisticRegression()
logistic_model.fit(X_pca, y_train)
y_pred = logistic_model.predict(X_test_pca)
accuracy = metrics.accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

y_pred.shape

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_pca, y_train)
y_pred = knn_model.predict(X_test_pca)
accuracy = metrics.accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.svm import LinearSVC

polynomial_svm_clf = Pipeline([
    ("poly_features", PolynomialFeatures(degree = 3)),
    ("svm_clf", LinearSVC(C = 10, loss = "hinge"))
])

'''X_train = pd.DataFrame(X_train)
y_train = pd.DataFrame(y_train)

# Now you can check the shape of the DataFrame
print(y_train.shape)
print(X_train.shape)'''

#y_train= y_train.reshape(-1, 1)
#y_test = y_test.reshape(-1, 1)

polynomial_svm_clf.fit(X_pca, y_train)

print(X_test.iloc[0])

X_test_pca = pca.fit_transform(X_test)

print(X_test_pca.shape)

polynomial_svm_clf.predict([X_test_pca[0]])

from sklearn.metrics import accuracy_score
y_pred = polynomial_svm_clf.predict(X_test_pca)

print(y_pred.shape)
print(y_test.shape)

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

"""Try with SVM kernels"""

from sklearn.svm import SVC

poly_kernel_svm_clf = Pipeline([
    ("scaler", StandardScaler()),
    ("svm_clf", SVC(kernel = "poly", degree = 3, coef0 = 1, C=5))
])

poly_kernel_svm_clf.fit(X_pca, y_train)

y_pred = poly_kernel_svm_clf.predict(X_test_pca)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

param_grid = {
    'svm_clf__C': [0.1, 1, 10],
    'svm_clf__gamma': [0.01, 0.1, 1],
    'svm_clf__degree': [2, 3, 4],
    'svm_clf__coef0': [-1, 0, 1]
}

from sklearn.model_selection import GridSearchCV
grid_search = GridSearchCV(estimator=poly_kernel_svm_clf, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the data
grid_search.fit(X_pca, y_train)

# Get the best hyperparameters and model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

# Evaluate the best model on the test set
accuracy = best_model.score(X_test_pca, y_test)

print("Best Hyperparameters:", best_params)
print("Accuracy:", accuracy)

'''from sklearn.linear_model import SGDClassifier

some_system = X_train.iloc[0]

sgd_clf = SGDClassifier(random_state = 42)
sgd_clf.fit(X_train, y_train)

sgd_clf.predict([some_system])'''

'''from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.model_selection import cross_val_predict

y_train_pred = cross_val_predict(sgd_clf, X_train, y_train, cv = 3)
y_exoplanet = (y_train == 2)
precision_score(y_exoplanet, y_train_pred, average = None)
recall_score(y_exoplanet, y_train_pred, average = None)
f1_score(y_exoplanet, y_train_pred, average = None)'''

"""Using a Binary MLP classifier"""

!pip import scikit-learning

!pip install tensorflow
import tensorflow as tf

from tensorflow import keras

X_train.shape

model = keras.models.Sequential([
    keras.layers.Dense(30, activation = "relu", input_shape = (3197,)),
    keras.layers.Dense(30,activation = "relu"),
    keras.layers.Dense(1, activation = "sigmoid")
])

model.compile(loss = "binary_crossentropy", optimizer = keras.optimizers.SGD(learning_rate =0.001 ), metrics = ["accuracy"])

history = model.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))

import pandas as pd
import matplotlib.pyplot as plt

pd.DataFrame(history.history).plot(figsize=(8,5))
plt.grid(True)

plt.show()

print(X_test.iloc[5].shape)

import numpy as np
X_new = X_test.iloc[5]

X_new = X_new.values.reshape(-1, 3197)
X_new= pd.DataFrame(X_new)

X_new.shape

y_pred = model.predict(X_new)
y_pred